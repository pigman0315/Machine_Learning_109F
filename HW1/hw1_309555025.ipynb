{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition & File input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#######################################################################\n",
    "data_t = None\n",
    "data_x = None\n",
    "train_t = []\n",
    "valid_t = []\n",
    "train_x = []\n",
    "valid_x = []\n",
    "D = 7\n",
    "feature_name = ['GRE_score','TOFEL_score','University_rating','SOP','LOR','CGPA','Research']\n",
    "# Data t: Chance_of_Admit \n",
    "# Data x: GRE_score,TOFEL_score,University_rating,SOP,LOR ,CGPA,Research\n",
    "#######################################################################\n",
    "def read_file():\n",
    "    global data_t, data_x\n",
    "    file_t = open(\"./dataset/data_T.csv\", mode = 'r')\n",
    "    file_x = open(\"./dataset/data_X.csv\", mode = 'r')\n",
    "    data_t = file_t.readlines()\n",
    "    data_x = file_x.readlines()\n",
    "    # process data T\n",
    "    for i in range(500):\n",
    "        data_t[i] = data_t[i].split(',')\n",
    "        data_t[i] = data_t[i][1].split('\\n')[0]\n",
    "        data_t[i] = float(data_t[i])\n",
    "    # process data X\n",
    "    for i in range(500):\n",
    "        data_x[i] = data_x[i].split(',')\n",
    "        data_x[i][D] = data_x[i][7].split('\\n')[0]\n",
    "        data_x[i] = data_x[i][1:]\n",
    "        for j in range(7):\n",
    "            data_x[i][j] = float(data_x[i][j])\n",
    "        \n",
    "    file_t.close()\n",
    "    file_t.close()\n",
    "def preprocess():\n",
    "    m = []\n",
    "    s = []\n",
    "    N = len(data_x)\n",
    "    for j in range(6):\n",
    "        tmp_list = []\n",
    "        for i in range(N):\n",
    "            tmp_list.append(data_x[i][j])\n",
    "        m.append(np.mean(tmp_list))\n",
    "        s.append(math.sqrt(np.var(tmp_list)))\n",
    "    for i in range(len(data_x)):\n",
    "        for j in range(6):\n",
    "            data_x[i][j] = (data_x[i][j] - m[j])/s[j]\n",
    "def split_dataset():\n",
    "    global train_t, train_x, test_t, test_x\n",
    "    for i in range(400):\n",
    "        train_t.append(data_t[i])\n",
    "        train_x.append(data_x[i])\n",
    "    for i in range(400,500):\n",
    "        valid_t.append(data_t[i])\n",
    "        valid_x.append(data_x[i])\n",
    "def error_func(x,t,w,N,M):\n",
    "    err = 0\n",
    "    for i in range(N):\n",
    "        err += (poly_func(x[i],w,M) - t[i])**2\n",
    "    err = err/(2*N)\n",
    "    return err\n",
    "def poly_func(x,w,M):\n",
    "    val = 0.0\n",
    "    # w is a 1D list\n",
    "    if(M==1): \n",
    "        val += w[0]\n",
    "        for i in range(D):\n",
    "            val += w[i+1]*x[i]\n",
    "    # M = 2\n",
    "    # w is a 1D list\n",
    "    elif(M==2):\n",
    "        val += w[0]\n",
    "        for i in range(1,D+1):\n",
    "            val += w[i]*x[i-1]\n",
    "        cnt = 8\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                val += w[cnt]*x[i]*x[j]\n",
    "                cnt +=1\n",
    "    # Poly\n",
    "    else: \n",
    "        val += w[0]\n",
    "        for i in range(1,D+1):\n",
    "            val += w[i]*x[i-1]\n",
    "        cnt = 8\n",
    "        for i in range(0,7):\n",
    "            for j in range(i,7):\n",
    "                val += w[cnt]*x[i]*x[j]\n",
    "                cnt +=1\n",
    "    return val\n",
    "def update_weights_1(x,t,w,learning_rate):\n",
    "    w_derive = [0]*(D+1)\n",
    "    N = len(x)\n",
    "    # find derive of w[0]\n",
    "    for i in range(N):\n",
    "        sum = 0\n",
    "        sum += w[0]\n",
    "        for j in range(D):\n",
    "            sum += w[j+1]*x[i][j]\n",
    "        sum -= t[i]\n",
    "        w_derive[0] += sum\n",
    "    # find derive of w[1]~w[7]\n",
    "    for cnt in range(1,D+1):\n",
    "        for i in range(N):\n",
    "            sum = 0\n",
    "            sum += w[0]\n",
    "            for j in range(D):\n",
    "                sum += w[j+1]*x[i][j]\n",
    "            sum -= t[i]\n",
    "            sum *= x[i][cnt-1]\n",
    "            w_derive[cnt] += sum\n",
    "\n",
    "    for i in range(D+1):\n",
    "        w[i] -= (w_derive[i]/float(N)) * learning_rate\n",
    "    \n",
    "    return w\n",
    "def update_weights_2(x,t,w,learning_rate):\n",
    "    w_derive = [0]*36\n",
    "    N = len(x)\n",
    "    # find derive of w[0]\n",
    "    for i in range(N):\n",
    "        sum = 0\n",
    "        sum += w[0]\n",
    "        for j in range(7):\n",
    "            sum += w[j+1]*x[i][j]\n",
    "        for j in range(7):\n",
    "            for k in range(7):\n",
    "                sum += w[(j+1)*7+(k+1)]*x[i][j]*x[i][k]\n",
    "        sum -= t[i]\n",
    "        w_derive[0] += sum\n",
    "    # find derive of w[1]~w[7]\n",
    "    for cnt in range(1,8):\n",
    "        for i in range(N):\n",
    "            sum = 0\n",
    "            sum += w[0]\n",
    "            for j in range(7):\n",
    "                sum += w[j+1]*x[i][j]\n",
    "            for j in range(7):\n",
    "                for k in range(7):\n",
    "                    sum += w[(j+1)*7+(k+1)]*x[i][j]*x[i][k]\n",
    "            sum -= t[i]\n",
    "            sum *= x[i][cnt-1]\n",
    "            w_derive[cnt] += sum\n",
    "    # find derive of w[8]~w[56]\n",
    "    for cnt in range(8,36):\n",
    "        for i in range(N):\n",
    "            sum = 0\n",
    "            sum += w[0]\n",
    "            for j in range(7):\n",
    "                sum += w[j+1]*x[i][j]\n",
    "            for j in range(7):\n",
    "                for k in range(7):\n",
    "                    sum += w[(j+1)*7+(k+1)]*x[i][j]*x[i][k]\n",
    "            sum -= t[i]\n",
    "            \n",
    "            sum *= x[i][((cnt-1)//7)-1]*x[i][(cnt-1)%7]\n",
    "            w_derive[cnt] += sum\n",
    "    # complete w[0] ~ w[56]\n",
    "    for i in range(36):\n",
    "         w[i] -= (w_derive[i]/float(N)) * learning_rate\n",
    "    return w\n",
    "def train_1(train_x,train_t,learning_rate,iter_num):\n",
    "    w = [0]*(D+1)\n",
    "    w[0] = 1\n",
    "    err_list = []\n",
    "    N = len(train_x)\n",
    "    for i in range(iter_num):\n",
    "        w = update_weights_1(train_x,train_t, w, learning_rate)\n",
    "        \n",
    "        tmp_err = error_func(train_x,train_t,w,N,1)\n",
    "        err_list.append(tmp_err)\n",
    "        #print(tmp_err)\n",
    "    return w\n",
    "def train_2(train_x,train_t,learning_rate,iter_num):\n",
    "    w = [0]*36\n",
    "    w[0] = 1\n",
    "    \n",
    "    err_list = []\n",
    "    N = len(train_x)\n",
    "    for i in range(iter_num):\n",
    "        w = update_weights_2(train_x,train_t, w, learning_rate)\n",
    "        \n",
    "        tmp_err = error_func(train_x,train_t,w,N,2)\n",
    "        err_list.append(tmp_err)\n",
    "    return w\n",
    "def calculate_RMS(x,t,w,M):\n",
    "    N = len(x)\n",
    "    RMS = 0.0\n",
    "    #print(w)\n",
    "    for i in range(N):\n",
    "        RMS += (poly_func(x[i],w,M) - t[i])**2\n",
    "    RMS = math.sqrt(RMS/float(N))\n",
    "    return RMS\n",
    "def select_feature(f_num):\n",
    "    t_x = [0]*400\n",
    "    v_x = [0]*100\n",
    "    for i in range(400):\n",
    "        t_x[i] = []\n",
    "        for n in f_num:\n",
    "            t_x[i].append(train_x[i][n])\n",
    "    for i in range(100):\n",
    "        v_x[i] = []\n",
    "        for n in f_num:\n",
    "            v_x[i].append(valid_x[i][n])\n",
    "    return t_x,v_x\n",
    "def apply_poly(train_x,train_t,l):\n",
    "    x = np.array(train_x,dtype='float')\n",
    "    t = np.array(train_t,dtype='float').reshape(400,1)\n",
    "    one = np.array([[1]*400],dtype='float')\n",
    "    # add coefficient for w0\n",
    "    x = np.insert(x,0,values=one, axis = 1)\n",
    "    # x = x1 +...+x7 +x1x1 + x1x2 + ....+ x7x7 (total 36 items)\n",
    "    for i in range(7):\n",
    "        for j in range(i,7):\n",
    "            tmp = np.array([1]*400,dtype='float').reshape(400,1)\n",
    "            for c in range(400):\n",
    "                tmp[c] = train_x[c][i]*train_x[c][j]    \n",
    "            x = np.append(x,values=tmp, axis = 1)\n",
    "    if(l == None):\n",
    "        w = np.dot(np.dot(np.linalg.pinv(np.dot(x.transpose(),x)),x.transpose()),t)\n",
    "    else:\n",
    "        w = np.dot(np.dot(np.linalg.pinv(np.dot(x.transpose(),x)++np.eye(36)*l),x.transpose()),t)\n",
    "    return w\n",
    "def least_square_sol_1(train_x,train_t):\n",
    "    x = np.array(train_x,dtype='float')\n",
    "    t = np.array(train_t,dtype='float').reshape(400,1)\n",
    "    one = np.array([[1]*400],dtype='float')\n",
    "    # add coefficient for w0\n",
    "    x = np.insert(x,0,values=one, axis = 1)\n",
    "    #\n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)),x.transpose()),t)\n",
    "    return w\n",
    "def reg_least_square_sol_1(train_x,train_t,l):\n",
    "    x = np.array(train_x,dtype='float')\n",
    "    t = np.array(train_t,dtype='float').reshape(400,1)\n",
    "    one = np.array([[1]*400],dtype='float')\n",
    "    # add coefficient for w0\n",
    "    x = np.insert(x,0,values=one, axis = 1)\n",
    "    #\n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(x.transpose(),x)+np.eye(8)*l),x.transpose()),t)\n",
    "    return w\n",
    "def least_square_sol_2(train_x,train_t):\n",
    "    x = np.array(train_x,dtype='float')\n",
    "    t = np.array(train_t,dtype='float').reshape(400,1)\n",
    "    one = np.array([[1]*400],dtype='float')\n",
    "    # add coefficient for w0\n",
    "    x = np.insert(x,0,values=one, axis = 1)\n",
    "    # \n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            tmp = np.array([1]*400,dtype='float').reshape(400,1)\n",
    "            for c in range(400):\n",
    "                tmp[c] = train_x[c][i]*train_x[c][j]    \n",
    "            x = np.append(x,values=tmp, axis = 1)\n",
    "    w = np.dot(np.dot(np.linalg.pinv(np.dot(x.transpose(),x)),x.transpose()),t)\n",
    "    return w\n",
    "def reg_least_square_sol_2(train_x,train_t,l):\n",
    "    x = np.array(train_x,dtype='float')\n",
    "    t = np.array(train_t,dtype='float').reshape(400,1)\n",
    "    one = np.array([[1]*400],dtype='float')\n",
    "    # add coefficient for w0\n",
    "    x = np.insert(x,0,values=one, axis = 1)\n",
    "    # \n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            tmp = np.array([1]*400,dtype='float').reshape(400,1)\n",
    "            for c in range(400):\n",
    "                tmp[c] = train_x[c][i]*train_x[c][j]    \n",
    "            x = np.append(x,values=tmp, axis = 1)\n",
    "    w = np.dot(np.dot(np.linalg.pinv(np.dot(x.transpose(),x)+np.eye(57)*l),x.transpose()),t)\n",
    "    return w\n",
    "############################################################\n",
    "read_file()\n",
    "#preprocess()\n",
    "split_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Feature select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS error of training set (M=1) =  0.06314185017282051\n",
      "RMS error of validation set (M=1) =  0.04293220746251964\n",
      "\n",
      "RMS error of training set (M=2) =  0.06015696005703246\n",
      "RMS error of validation set (M=2) =  0.048938858565618436\n",
      "\n",
      "Most contributive feature =  CGPA\n"
     ]
    }
   ],
   "source": [
    "# M = 1\n",
    "w_1 = least_square_sol_1(train_x,train_t)\n",
    "RMS_train_1 = calculate_RMS(train_x,train_t,w_1,1)\n",
    "RMS_valid_1 = calculate_RMS(valid_x,valid_t,w_1,1)\n",
    "print(\"RMS error of training set (M=1) = \", RMS_train_1)\n",
    "print(\"RMS error of validation set (M=1) = \", RMS_valid_1)\n",
    "# M = 2\n",
    "w = least_square_sol_2(train_x,train_t)\n",
    "RMS_train = calculate_RMS(train_x,train_t,w,2)\n",
    "RMS_valid = calculate_RMS(valid_x,valid_t,w,2)\n",
    "print(\"\\nRMS error of training set (M=2) = \", RMS_train)\n",
    "print(\"RMS error of validation set (M=2) = \", RMS_valid)\n",
    "# Find most contributive feature\n",
    "contributive_feature_num = -1\n",
    "val = 0\n",
    "for i in range(7):\n",
    "    if(w_1[i+1]**2 > val):\n",
    "        contributive_feature_num = i\n",
    "        val = w_1[i+1]**2\n",
    "print(\"\\nMost contributive feature = \", feature_name[contributive_feature_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2(b) Introduce basis function to previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMS error of training set (Poly) =  0.06015694892729082\n",
      "RMS error of validation set (Poly) =  0.04894526470755938\n"
     ]
    }
   ],
   "source": [
    "# Polynomial basis function\n",
    "w = apply_poly(train_x,train_t,None)\n",
    "RMS_train = calculate_RMS(train_x,train_t,w,3)\n",
    "RMS_valid = calculate_RMS(valid_x,valid_t,w,3)\n",
    "print(\"\\nRMS error of training set (Poly) = \", RMS_train)\n",
    "print(\"RMS error of validation set (Poly) = \", RMS_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2(C) N-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMS error of training set(K-fold, M = 1) =  0.058796957934396335\n",
      "RMS error of valid set(K-fold, M = 1) =  0.05946970564727\n",
      "\n",
      "RMS error of training set(K-fold, M = 2) =  0.05579987637150844\n",
      "RMS error of valid set(K-fold, M = 2) =  0.06395489510640454\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross-validation\n",
    "#\n",
    "v_x = []\n",
    "v_x.append(data_x[0:100])\n",
    "v_x.append(data_x[100:200])\n",
    "v_x.append(data_x[200:300])\n",
    "v_x.append(data_x[300:400])\n",
    "v_x.append(data_x[400:500])\n",
    "v_t = []\n",
    "v_t.append(data_t[0:100])\n",
    "v_t.append(data_t[100:200])\n",
    "v_t.append(data_t[200:300])\n",
    "v_t.append(data_t[300:400])\n",
    "v_t.append(data_t[400:500])\n",
    "#\n",
    "t_t = []\n",
    "t_t.append(v_t[1])\n",
    "t_t[0] = np.append(t_t[0],v_t[2],0)\n",
    "t_t[0] = np.append(t_t[0],v_t[3],0)\n",
    "t_t[0] = np.append(t_t[0],v_t[4],0)\n",
    "\n",
    "t_t.append(v_t[0])\n",
    "t_t[1] = np.append(t_t[1],v_t[2],0)\n",
    "t_t[1] = np.append(t_t[1],v_t[3],0)\n",
    "t_t[1] = np.append(t_t[1],v_t[4],0)\n",
    "\n",
    "t_t.append(v_t[0])\n",
    "t_t[2] = np.append(t_t[2],v_t[1],0)\n",
    "t_t[2] = np.append(t_t[2],v_t[3],0)\n",
    "t_t[2] = np.append(t_t[2],v_t[4],0)\n",
    "\n",
    "t_t.append(v_t[0])\n",
    "t_t[3] = np.append(t_t[3],v_t[1],0)\n",
    "t_t[3] = np.append(t_t[3],v_t[2],0)\n",
    "t_t[3] = np.append(t_t[3],v_t[4],0)\n",
    "\n",
    "t_t.append(v_t[0])\n",
    "t_t[4] = np.append(t_t[4],v_t[1],0)\n",
    "t_t[4] = np.append(t_t[4],v_t[2],0)\n",
    "t_t[4] = np.append(t_t[4],v_t[3],0)\n",
    "#\n",
    "t_x = []\n",
    "t_x.append(v_x[1])\n",
    "t_x[0] = np.append(t_x[0],v_x[2],0)\n",
    "t_x[0] = np.append(t_x[0],v_x[3],0)\n",
    "t_x[0] = np.append(t_x[0],v_x[4],0)\n",
    "\n",
    "t_x.append(v_x[0])\n",
    "t_x[1] = np.append(t_x[1],v_x[2],0)\n",
    "t_x[1] = np.append(t_x[1],v_x[3],0)\n",
    "t_x[1] = np.append(t_x[1],v_x[4],0)\n",
    "\n",
    "t_x.append(v_x[0])\n",
    "t_x[2] = np.append(t_x[2],v_x[1],0)\n",
    "t_x[2] = np.append(t_x[2],v_x[3],0)\n",
    "t_x[2] = np.append(t_x[2],v_x[4],0)\n",
    "\n",
    "t_x.append(v_x[0])\n",
    "t_x[3] = np.append(t_x[3],v_x[1],0)\n",
    "t_x[3] = np.append(t_x[3],v_x[2],0)\n",
    "t_x[3] = np.append(t_x[3],v_x[4],0)\n",
    "\n",
    "t_x.append(v_x[0])\n",
    "t_x[4] = np.append(t_x[4],v_x[1],0)\n",
    "t_x[4] = np.append(t_x[4],v_x[2],0)\n",
    "t_x[4] = np.append(t_x[4],v_x[3],0)\n",
    "# N-fold\n",
    "RMS_train_m = 0\n",
    "RMS_valid_m = 0\n",
    "for i in range(5):\n",
    "    w = least_square_sol_1(t_x[i],t_t[i])\n",
    "    RMS_train_m += calculate_RMS(t_x[i],t_t[i],w,1)\n",
    "    RMS_valid_m += calculate_RMS(v_x[i],v_t[i],w,1)\n",
    "\n",
    "print(\"\\nRMS error of training set(K-fold, M = 1) = \", RMS_train_m/5.0)\n",
    "print(\"RMS error of valid set(K-fold, M = 1) = \", RMS_valid_m/5.0)\n",
    "RMS_train_m = 0\n",
    "RMS_valid_m = 0\n",
    "for i in range(5):\n",
    "    w = least_square_sol_2(t_x[i],t_t[i])\n",
    "    RMS_train_m += calculate_RMS(t_x[i],t_t[i],w,2)\n",
    "    RMS_valid_m += calculate_RMS(v_x[i],v_t[i],w,2)\n",
    "print(\"\\nRMS error of training set(K-fold, M = 2) = \", RMS_train_m/5.0)\n",
    "print(\"RMS error of valid set(K-fold, M = 2) = \", RMS_valid_m/5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3(b) Use MAP to retest the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMS error of training set (Poly, lambda = 1) =  0.06044961263428089\n",
      "RMS error of validation set (Poly, lambda = 1) =  0.04626932554473747\n",
      "\n",
      "RMS error of training set (Poly, lambda = 100) =  0.06164013757778419\n",
      "RMS error of validation set (Poly, lambda = 100) =  0.04556290207786235\n",
      "\n",
      "RMS error of training set (Poly, lambda = 10000) =  0.06337523725922141\n",
      "RMS error of validation set (Poly, lambda = 10000) =  0.04347689084900574\n",
      "\n",
      "RMS error of training set(K-fold, MAP, lambda = 1, M = 1) =  0.06422023057691623\n",
      "RMS error of valid set(K-fold, MAP, lambda = 1, M = 1) =  0.06524071081489292\n",
      "\n",
      "RMS error of training set(K-fold, MAP, lambda = 100, M = 1) =  0.0739798744796576\n",
      "RMS error of valid set(K-fold, MAP, lambda = 100, M = 1) =  0.07603777114413872\n",
      "\n",
      "RMS error of training set(K-fold, MAP, lambda = 10000, M = 1) =  0.1081575913783254\n",
      "RMS error of valid set(K-fold, MAP, lambda = 10000, M = 1) =  0.10805782204611139\n"
     ]
    }
   ],
   "source": [
    "# Poly MAP\n",
    "w = apply_poly(train_x,train_t,1)\n",
    "RMS_train = calculate_RMS(train_x,train_t,w,3)\n",
    "RMS_valid = calculate_RMS(valid_x,valid_t,w,3)\n",
    "print(\"\\nRMS error of training set (Poly, lambda = 1) = \", RMS_train)\n",
    "print(\"RMS error of validation set (Poly, lambda = 1) = \", RMS_valid)\n",
    "w = apply_poly(train_x,train_t,100)\n",
    "RMS_train = calculate_RMS(train_x,train_t,w,3)\n",
    "RMS_valid = calculate_RMS(valid_x,valid_t,w,3)\n",
    "print(\"\\nRMS error of training set (Poly, lambda = 100) = \", RMS_train)\n",
    "print(\"RMS error of validation set (Poly, lambda = 100) = \", RMS_valid)\n",
    "w = apply_poly(train_x,train_t,10000)\n",
    "RMS_train = calculate_RMS(train_x,train_t,w,3)\n",
    "RMS_valid = calculate_RMS(valid_x,valid_t,w,3)\n",
    "print(\"\\nRMS error of training set (Poly, lambda = 10000) = \", RMS_train)\n",
    "print(\"RMS error of validation set (Poly, lambda = 10000) = \", RMS_valid)\n",
    "# N-fold MAP\n",
    "RMS_train_m = 0\n",
    "RMS_valid_m = 0\n",
    "for i in range(5):\n",
    "    w = reg_least_square_sol_1(t_x[i],t_t[i],1)\n",
    "    RMS_train_m += calculate_RMS(t_x[i],t_t[i],w,1)\n",
    "    RMS_valid_m += calculate_RMS(v_x[i],v_t[i],w,1)\n",
    "\n",
    "print(\"\\nRMS error of training set(K-fold, MAP, lambda = 1, M = 1) = \", RMS_train_m/5.0)\n",
    "print(\"RMS error of valid set(K-fold, MAP, lambda = 1, M = 1) = \", RMS_valid_m/5.0)\n",
    "RMS_train_m = 0\n",
    "RMS_valid_m = 0\n",
    "for i in range(5):\n",
    "    w = reg_least_square_sol_1(t_x[i],t_t[i],100)\n",
    "    RMS_train_m += calculate_RMS(t_x[i],t_t[i],w,1)\n",
    "    RMS_valid_m += calculate_RMS(v_x[i],v_t[i],w,1)\n",
    "\n",
    "print(\"\\nRMS error of training set(K-fold, MAP, lambda = 100, M = 1) = \", RMS_train_m/5.0)\n",
    "print(\"RMS error of valid set(K-fold, MAP, lambda = 100, M = 1) = \", RMS_valid_m/5.0)\n",
    "RMS_train_m = 0\n",
    "RMS_valid_m = 0\n",
    "for i in range(5):\n",
    "    w = reg_least_square_sol_1(t_x[i],t_t[i],10000)\n",
    "    RMS_train_m += calculate_RMS(t_x[i],t_t[i],w,1)\n",
    "    RMS_valid_m += calculate_RMS(v_x[i],v_t[i],w,1)\n",
    "\n",
    "print(\"\\nRMS error of training set(K-fold, MAP, lambda = 10000, M = 1) = \", RMS_train_m/5.0)\n",
    "print(\"RMS error of valid set(K-fold, MAP, lambda = 10000, M = 1) = \", RMS_valid_m/5.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
